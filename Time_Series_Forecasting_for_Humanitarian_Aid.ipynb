{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/drive/1K_GfQBClmBbnH5xSiOwtZ5LVc0-iMKxs#scrollTo=csOn5BzX1_q3\" target=\"_blank\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clone Git Repositories"
      ],
      "metadata": {
        "id": "izsiJrBv5iO9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-lDCQJaFBZWF",
        "outputId": "c59aaf0c-e8e5-47f1-d963-9ac28e83f75c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'humanitarian_aid_dataset'...\n",
            "remote: Enumerating objects: 105, done.\u001b[K\n",
            "remote: Counting objects: 100% (105/105), done.\u001b[K\n",
            "remote: Compressing objects: 100% (78/78), done.\u001b[K\n",
            "remote: Total 105 (delta 34), reused 74 (delta 25), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (105/105), 55.45 KiB | 13.86 MiB/s, done.\n",
            "Resolving deltas: 100% (34/34), done.\n",
            "Cloning into 'tsf_model'...\n",
            "remote: Enumerating objects: 81, done.\u001b[K\n",
            "remote: Counting objects: 100% (81/81), done.\u001b[K\n",
            "remote: Compressing objects: 100% (80/80), done.\u001b[K\n",
            "remote: Total 81 (delta 43), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (81/81), 45.29 KiB | 2.52 MiB/s, done.\n"
          ]
        }
      ],
      "source": [
        "! git clone https://github.com/PoliTO-ADSP-United-Nations-Project/humanitarian_aid_dataset\n",
        "! git clone https://github.com/PoliTO-ADSP-United-Nations-Project/tsf_model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Imports and Install"
      ],
      "metadata": {
        "id": "tRYcVYT_kWjK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install darts\n",
        "!pip uninstall matplotlib -y\n",
        "!pip install matplotlib==3.1.3\n",
        "!pip install pytorch-lightning\n",
        "!pip install pytorch-forecasting\n",
        "!pip uninstall statsmodels  -y\n",
        "!pip install statsmodels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHlup1XQbkBa",
        "outputId": "2775a19f-1ee7-491a-fd11-569cbae924e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting darts\n",
            "  Downloading darts-0.23.1-py3-none-any.whl (592 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m592.0/592.0 KB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting matplotlib>=3.3.0\n",
            "  Downloading matplotlib-3.6.3-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (9.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m49.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pmdarima>=1.8.0\n",
            "  Downloading pmdarima-2.0.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.8/dist-packages (from darts) (1.3.5)\n",
            "Collecting shap>=0.40.0\n",
            "  Downloading shap-0.41.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (575 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m575.9/575.9 KB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nfoursid>=1.0.0\n",
            "  Downloading nfoursid-1.0.1-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.8/dist-packages (from darts) (1.13.1+cu116)\n",
            "Requirement already satisfied: holidays>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from darts) (0.19)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.8/dist-packages (from darts) (1.21.6)\n",
            "Requirement already satisfied: prophet>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from darts) (1.1.2)\n",
            "Collecting catboost>=1.0.6\n",
            "  Downloading catboost-1.1.1-cp38-none-manylinux1_x86_64.whl (76.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.6/76.6 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: xarray>=0.17.0 in /usr/local/lib/python3.8/dist-packages (from darts) (2022.12.0)\n",
            "Collecting statsmodels>=0.13.0\n",
            "  Downloading statsmodels-0.13.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m75.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tbats>=1.1.0\n",
            "  Downloading tbats-1.1.2-py3-none-any.whl (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 KB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.60.0 in /usr/local/lib/python3.8/dist-packages (from darts) (4.64.1)\n",
            "Collecting xgboost>=1.6.0\n",
            "  Downloading xgboost-1.7.3-py3-none-manylinux2014_x86_64.whl (193.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from darts) (1.0.2)\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.8/dist-packages (from darts) (2.25.1)\n",
            "Collecting lightgbm>=3.2.0\n",
            "  Downloading lightgbm-3.3.5-py3-none-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m94.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.8/dist-packages (from darts) (1.7.3)\n",
            "Collecting pytorch-lightning>=1.5.0\n",
            "  Downloading pytorch_lightning-1.9.0-py3-none-any.whl (825 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m825.8/825.8 KB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.16.0 in /usr/local/lib/python3.8/dist-packages (from darts) (1.2.0)\n",
            "Collecting pyod>=0.9.5\n",
            "  Downloading pyod-1.0.7.tar.gz (147 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.7/147.7 KB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting statsforecast>=1.0.0\n",
            "  Downloading statsforecast-1.4.0-py3-none-any.whl (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 KB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: plotly in /usr/local/lib/python3.8/dist-packages (from catboost>=1.0.6->darts) (5.5.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from catboost>=1.0.6->darts) (1.15.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.8/dist-packages (from catboost>=1.0.6->darts) (0.10.1)\n",
            "Requirement already satisfied: PyMeeus in /usr/local/lib/python3.8/dist-packages (from holidays>=0.11.1->darts) (0.5.12)\n",
            "Requirement already satisfied: convertdate>=2.3.0 in /usr/local/lib/python3.8/dist-packages (from holidays>=0.11.1->darts) (2.4.0)\n",
            "Requirement already satisfied: korean-lunar-calendar in /usr/local/lib/python3.8/dist-packages (from holidays>=0.11.1->darts) (0.3.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.8/dist-packages (from holidays>=0.11.1->darts) (2.8.2)\n",
            "Requirement already satisfied: hijri-converter in /usr/local/lib/python3.8/dist-packages (from holidays>=0.11.1->darts) (2.2.4)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.8/dist-packages (from lightgbm>=3.2.0->darts) (0.38.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.3.0->darts) (0.11.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.3.0->darts) (3.0.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.3.0->darts) (23.0)\n",
            "Collecting fonttools>=4.22.0\n",
            "  Downloading fonttools-4.38.0-py3-none-any.whl (965 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m965.4/965.4 KB\u001b[0m \u001b[31m69.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.3.0->darts) (7.1.2)\n",
            "Collecting contourpy>=1.0.1\n",
            "  Downloading contourpy-1.0.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (300 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.0/300.0 KB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.3.0->darts) (1.4.4)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.0.5->darts) (2022.7.1)\n",
            "Requirement already satisfied: Cython!=0.29.18,!=0.29.31,>=0.29 in /usr/local/lib/python3.8/dist-packages (from pmdarima>=1.8.0->darts) (0.29.33)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.8/dist-packages (from pmdarima>=1.8.0->darts) (1.24.3)\n",
            "Requirement already satisfied: setuptools!=50.0.0,>=38.6.0 in /usr/local/lib/python3.8/dist-packages (from pmdarima>=1.8.0->darts) (57.4.0)\n",
            "Requirement already satisfied: LunarCalendar>=0.0.9 in /usr/local/lib/python3.8/dist-packages (from prophet>=1.1.1->darts) (0.0.9)\n",
            "Requirement already satisfied: cmdstanpy>=1.0.4 in /usr/local/lib/python3.8/dist-packages (from prophet>=1.1.1->darts) (1.1.0)\n",
            "Requirement already satisfied: numba>=0.51 in /usr/local/lib/python3.8/dist-packages (from pyod>=0.9.5->darts) (0.56.4)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning>=1.5.0->darts) (4.4.0)\n",
            "Collecting lightning-utilities>=0.4.2\n",
            "  Downloading lightning_utilities-0.6.0.post0-py3-none-any.whl (18 kB)\n",
            "Collecting torchmetrics>=0.7.0\n",
            "  Downloading torchmetrics-0.11.1-py3-none-any.whl (517 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m517.2/517.2 KB\u001b[0m \u001b[31m51.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning>=1.5.0->darts) (2023.1.0)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning>=1.5.0->darts) (6.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.22.0->darts) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.22.0->darts) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.22.0->darts) (4.0.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.0.1->darts) (3.1.0)\n",
            "Collecting slicer==0.0.7\n",
            "  Downloading slicer-0.0.7-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.8/dist-packages (from shap>=0.40.0->darts) (2.2.1)\n",
            "Requirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.8/dist-packages (from statsmodels>=0.13.0->darts) (0.5.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.8/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning>=1.5.0->darts) (3.8.3)\n",
            "Requirement already satisfied: ephem>=3.7.5.3 in /usr/local/lib/python3.8/dist-packages (from LunarCalendar>=0.0.9->prophet>=1.1.1->darts) (4.1.4)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.8/dist-packages (from numba>=0.51->pyod>=0.9.5->darts) (6.0.0)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.8/dist-packages (from numba>=0.51->pyod>=0.9.5->darts) (0.39.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from plotly->catboost>=1.0.6->darts) (8.1.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning>=1.5.0->darts) (22.2.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning>=1.5.0->darts) (4.0.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning>=1.5.0->darts) (1.3.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning>=1.5.0->darts) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning>=1.5.0->darts) (1.8.2)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning>=1.5.0->darts) (2.1.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning>=1.5.0->darts) (1.3.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata->numba>=0.51->pyod>=0.9.5->darts) (3.12.0)\n",
            "Building wheels for collected packages: pyod\n",
            "  Building wheel for pyod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyod: filename=pyod-1.0.7-py3-none-any.whl size=181101 sha256=1035a5a52d90ab38432317d520e8d952b40b5ad6e588ebc54b7cbfc8d9815d68\n",
            "  Stored in directory: /root/.cache/pip/wheels/f7/e2/c1/1c7fd8b261e72411f6509afb429c84532e40ddcd96074473f4\n",
            "Successfully built pyod\n",
            "Installing collected packages: slicer, lightning-utilities, fonttools, contourpy, xgboost, torchmetrics, matplotlib, statsmodels, shap, nfoursid, lightgbm, catboost, statsforecast, pytorch-lightning, pyod, pmdarima, tbats, darts\n",
            "  Attempting uninstall: xgboost\n",
            "    Found existing installation: xgboost 0.90\n",
            "    Uninstalling xgboost-0.90:\n",
            "      Successfully uninstalled xgboost-0.90\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.2.2\n",
            "    Uninstalling matplotlib-3.2.2:\n",
            "      Successfully uninstalled matplotlib-3.2.2\n",
            "  Attempting uninstall: statsmodels\n",
            "    Found existing installation: statsmodels 0.12.2\n",
            "    Uninstalling statsmodels-0.12.2:\n",
            "      Successfully uninstalled statsmodels-0.12.2\n",
            "  Attempting uninstall: lightgbm\n",
            "    Found existing installation: lightgbm 2.2.3\n",
            "    Uninstalling lightgbm-2.2.3:\n",
            "      Successfully uninstalled lightgbm-2.2.3\n",
            "Successfully installed catboost-1.1.1 contourpy-1.0.7 darts-0.23.1 fonttools-4.38.0 lightgbm-3.3.5 lightning-utilities-0.6.0.post0 matplotlib-3.6.3 nfoursid-1.0.1 pmdarima-2.0.2 pyod-1.0.7 pytorch-lightning-1.9.0 shap-0.41.0 slicer-0.0.7 statsforecast-1.4.0 statsmodels-0.13.5 tbats-1.1.2 torchmetrics-0.11.1 xgboost-1.7.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "mpl_toolkits"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: matplotlib 3.6.3\n",
            "Uninstalling matplotlib-3.6.3:\n",
            "  Successfully uninstalled matplotlib-3.6.3\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting matplotlib==3.1.3\n",
            "  Downloading matplotlib-3.1.3-cp38-cp38-manylinux1_x86_64.whl (13.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.1.3) (1.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.1.3) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.1.3) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.1.3) (0.11.0)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.1.3) (1.21.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib==3.1.3) (1.15.0)\n",
            "Installing collected packages: matplotlib\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "nfoursid 1.0.1 requires matplotlib>=3.3, but you have matplotlib 3.1.3 which is incompatible.\n",
            "darts 0.23.1 requires matplotlib>=3.3.0, but you have matplotlib 3.1.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed matplotlib-3.1.3\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.8/dist-packages (1.9.0)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning) (1.21.6)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning) (1.13.1+cu116)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning) (4.4.0)\n",
            "Requirement already satisfied: torchmetrics>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning) (0.11.1)\n",
            "Requirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning) (23.0)\n",
            "Requirement already satisfied: lightning-utilities>=0.4.2 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning) (0.6.0.post0)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning) (4.64.1)\n",
            "Requirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning) (2023.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning) (2.25.1)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.8/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning) (3.8.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.3.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (22.2.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (2.1.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.8.2)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (4.0.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (2.10)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytorch-forecasting\n",
            "  Downloading pytorch_forecasting-0.10.3-py3-none-any.whl (141 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.4/141.4 KB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytorch-lightning<2.0.0,>=1.2.4 in /usr/local/lib/python3.8/dist-packages (from pytorch-forecasting) (1.9.0)\n",
            "Requirement already satisfied: torch<2.0,>=1.7 in /usr/local/lib/python3.8/dist-packages (from pytorch-forecasting) (1.13.1+cu116)\n",
            "Requirement already satisfied: scikit-learn<1.2,>=0.24 in /usr/local/lib/python3.8/dist-packages (from pytorch-forecasting) (1.0.2)\n",
            "Collecting scipy<2.0,>=1.8\n",
            "  Downloading scipy-1.10.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.5/34.5 MB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: statsmodels in /usr/local/lib/python3.8/dist-packages (from pytorch-forecasting) (0.13.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from pytorch-forecasting) (3.1.3)\n",
            "Collecting optuna<3.0.0,>=2.3.0\n",
            "  Downloading optuna-2.10.1-py3-none-any.whl (308 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m308.2/308.2 KB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas<2.0.0,>=1.3.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-forecasting) (1.3.5)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.8/dist-packages (from optuna<3.0.0,>=2.3.0->pytorch-forecasting) (6.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from optuna<3.0.0,>=2.3.0->pytorch-forecasting) (1.21.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from optuna<3.0.0,>=2.3.0->pytorch-forecasting) (4.64.1)\n",
            "Collecting alembic\n",
            "  Downloading alembic-1.9.2-py3-none-any.whl (210 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.6/210.6 KB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorlog\n",
            "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting cmaes>=0.8.2\n",
            "  Downloading cmaes-0.9.1-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from optuna<3.0.0,>=2.3.0->pytorch-forecasting) (23.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from optuna<3.0.0,>=2.3.0->pytorch-forecasting) (2.0.0)\n",
            "Collecting cliff\n",
            "  Downloading cliff-4.1.0-py3-none-any.whl (81 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.0/81.0 KB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas<2.0.0,>=1.3.0->pytorch-forecasting) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas<2.0.0,>=1.3.0->pytorch-forecasting) (2.8.2)\n",
            "Requirement already satisfied: torchmetrics>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning<2.0.0,>=1.2.4->pytorch-forecasting) (0.11.1)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning<2.0.0,>=1.2.4->pytorch-forecasting) (4.4.0)\n",
            "Requirement already satisfied: lightning-utilities>=0.4.2 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning<2.0.0,>=1.2.4->pytorch-forecasting) (0.6.0.post0)\n",
            "Requirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning<2.0.0,>=1.2.4->pytorch-forecasting) (2023.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn<1.2,>=0.24->pytorch-forecasting) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn<1.2,>=0.24->pytorch-forecasting) (1.2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->pytorch-forecasting) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->pytorch-forecasting) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->pytorch-forecasting) (0.11.0)\n",
            "Requirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.8/dist-packages (from statsmodels->pytorch-forecasting) (0.5.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.8/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning<2.0.0,>=1.2.4->pytorch-forecasting) (3.8.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning<2.0.0,>=1.2.4->pytorch-forecasting) (2.25.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from patsy>=0.5.2->statsmodels->pytorch-forecasting) (1.15.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.8/dist-packages (from sqlalchemy>=1.1.0->optuna<3.0.0,>=2.3.0->pytorch-forecasting) (2.0.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.8/dist-packages (from alembic->optuna<3.0.0,>=2.3.0->pytorch-forecasting) (6.0.0)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 KB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.8/dist-packages (from alembic->optuna<3.0.0,>=2.3.0->pytorch-forecasting) (5.10.2)\n",
            "Collecting autopage>=0.4.0\n",
            "  Downloading autopage-0.5.1-py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.8/dist-packages (from cliff->optuna<3.0.0,>=2.3.0->pytorch-forecasting) (3.6.0)\n",
            "Collecting cmd2>=1.0.0\n",
            "  Downloading cmd2-2.4.3-py3-none-any.whl (147 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.2/147.2 KB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting stevedore>=2.0.1\n",
            "  Downloading stevedore-4.1.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.0/50.0 KB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<2.0.0,>=1.2.4->pytorch-forecasting) (6.0.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<2.0.0,>=1.2.4->pytorch-forecasting) (1.3.3)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<2.0.0,>=1.2.4->pytorch-forecasting) (2.1.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<2.0.0,>=1.2.4->pytorch-forecasting) (1.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<2.0.0,>=1.2.4->pytorch-forecasting) (1.8.2)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<2.0.0,>=1.2.4->pytorch-forecasting) (4.0.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<2.0.0,>=1.2.4->pytorch-forecasting) (22.2.0)\n",
            "Collecting pyperclip>=1.6\n",
            "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.8/dist-packages (from cmd2>=1.0.0->cliff->optuna<3.0.0,>=2.3.0->pytorch-forecasting) (0.2.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata->alembic->optuna<3.0.0,>=2.3.0->pytorch-forecasting) (3.12.0)\n",
            "Collecting pbr!=2.1.0,>=2.0.0\n",
            "  Downloading pbr-5.11.1-py2.py3-none-any.whl (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.7/112.7 KB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.8/dist-packages (from Mako->alembic->optuna<3.0.0,>=2.3.0->pytorch-forecasting) (2.0.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning<2.0.0,>=1.2.4->pytorch-forecasting) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning<2.0.0,>=1.2.4->pytorch-forecasting) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning<2.0.0,>=1.2.4->pytorch-forecasting) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning<2.0.0,>=1.2.4->pytorch-forecasting) (4.0.0)\n",
            "Building wheels for collected packages: pyperclip\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11136 sha256=ac2171213475d64d105df18c7073ce6aea9bf347f9fd9a436b685186ef4f716f\n",
            "  Stored in directory: /root/.cache/pip/wheels/7f/1a/65/84ff8c386bec21fca6d220ea1f5498a0367883a78dd5ba6122\n",
            "Successfully built pyperclip\n",
            "Installing collected packages: pyperclip, scipy, pbr, Mako, colorlog, cmd2, cmaes, autopage, stevedore, alembic, cliff, optuna, pytorch-forecasting\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.7.3\n",
            "    Uninstalling scipy-1.7.3:\n",
            "      Successfully uninstalled scipy-1.7.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "darts 0.23.1 requires matplotlib>=3.3.0, but you have matplotlib 3.1.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Mako-1.2.4 alembic-1.9.2 autopage-0.5.1 cliff-4.1.0 cmaes-0.9.1 cmd2-2.4.3 colorlog-6.7.0 optuna-2.10.1 pbr-5.11.1 pyperclip-1.8.2 pytorch-forecasting-0.10.3 scipy-1.10.0 stevedore-4.1.1\n",
            "Found existing installation: statsmodels 0.13.5\n",
            "Uninstalling statsmodels-0.13.5:\n",
            "  Successfully uninstalled statsmodels-0.13.5\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting statsmodels\n",
            "  Using cached statsmodels-0.13.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.9 MB)\n",
            "Requirement already satisfied: pandas>=0.25 in /usr/local/lib/python3.8/dist-packages (from statsmodels) (1.3.5)\n",
            "Requirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.8/dist-packages (from statsmodels) (0.5.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from statsmodels) (1.21.6)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.8/dist-packages (from statsmodels) (23.0)\n",
            "Requirement already satisfied: scipy>=1.3 in /usr/local/lib/python3.8/dist-packages (from statsmodels) (1.10.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.25->statsmodels) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.25->statsmodels) (2.8.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from patsy>=0.5.2->statsmodels) (1.15.0)\n",
            "Installing collected packages: statsmodels\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "darts 0.23.1 requires matplotlib>=3.3.0, but you have matplotlib 3.1.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed statsmodels-0.13.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Run"
      ],
      "metadata": {
        "id": "13RNBNzc5aVR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%run --\"/content/humanitarian_aid_dataset/main.py\" "
      ],
      "metadata": {
        "id": "oSnzjuviEbTW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run statistical models"
      ],
      "metadata": {
        "id": "jjBuZS-Wkgx8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%run \"/content/tsf_model/statistical_models.py\" --dataset_dir=\"/content/final_dataset.csv\" --destination_country=\"ITA\" --model_name=\"ARIMA\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ppWc4DCGbdXu",
        "outputId": "a3baa2b2-8874-416c-e51e-1beff61e1d1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/10 [00:00<?, ?it/s]/usr/local/lib/python3.8/dist-packages/statsmodels/base/model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
            " 10%|█         | 1/10 [00:01<00:12,  1.36s/it]/usr/local/lib/python3.8/dist-packages/statsmodels/base/model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
            " 20%|██        | 2/10 [00:02<00:08,  1.10s/it]/usr/local/lib/python3.8/dist-packages/statsmodels/base/model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
            " 30%|███       | 3/10 [00:03<00:06,  1.01it/s]/usr/local/lib/python3.8/dist-packages/statsmodels/base/model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
            " 40%|████      | 4/10 [00:03<00:05,  1.07it/s]/usr/local/lib/python3.8/dist-packages/statsmodels/base/model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
            " 50%|█████     | 5/10 [00:04<00:04,  1.08it/s]/usr/local/lib/python3.8/dist-packages/statsmodels/base/model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
            " 60%|██████    | 6/10 [00:05<00:03,  1.10it/s]/usr/local/lib/python3.8/dist-packages/statsmodels/base/model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
            " 70%|███████   | 7/10 [00:06<00:02,  1.12it/s]/usr/local/lib/python3.8/dist-packages/statsmodels/base/model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
            " 80%|████████  | 8/10 [00:07<00:01,  1.11it/s]/usr/local/lib/python3.8/dist-packages/statsmodels/tsa/statespace/sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
            "  warn('Non-stationary starting autoregressive parameters'\n",
            "/usr/local/lib/python3.8/dist-packages/statsmodels/base/model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
            " 90%|█████████ | 9/10 [00:08<00:00,  1.11it/s]/usr/local/lib/python3.8/dist-packages/statsmodels/base/model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
            "100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30.711126313224675\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train TFT model"
      ],
      "metadata": {
        "id": "BShgZ3SLy1B5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python \"/content/tsf_model/tft_model.py\" --dataset_dir=\"/content/Final_TFT.csv\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "csOn5BzX1_q3",
        "outputId": "764de6fb-bbf7-4235-e50b-d5b5af8a91fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Global seed set to 0\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.8/dist-packages/pytorch_lightning/utilities/parsing.py:262: UserWarning: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
            "  rank_zero_warn(\n",
            "/usr/local/lib/python3.8/dist-packages/pytorch_lightning/utilities/parsing.py:262: UserWarning: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.\n",
            "  rank_zero_warn(\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "   | Name                               | Type                            | Params\n",
            "----------------------------------------------------------------------------------------\n",
            "0  | loss                               | QuantileLoss                    | 0     \n",
            "1  | logging_metrics                    | ModuleList                      | 0     \n",
            "2  | input_embeddings                   | MultiEmbedding                  | 288   \n",
            "3  | prescalers                         | ModuleDict                      | 176   \n",
            "4  | static_variable_selection          | VariableSelectionNetwork        | 2.6 K \n",
            "5  | encoder_variable_selection         | VariableSelectionNetwork        | 4.6 K \n",
            "6  | decoder_variable_selection         | VariableSelectionNetwork        | 1.3 K \n",
            "7  | static_context_variable_selection  | GatedResidualNetwork            | 1.1 K \n",
            "8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 1.1 K \n",
            "9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 1.1 K \n",
            "10 | static_context_enrichment          | GatedResidualNetwork            | 1.1 K \n",
            "11 | lstm_encoder                       | LSTM                            | 2.2 K \n",
            "12 | lstm_decoder                       | LSTM                            | 2.2 K \n",
            "13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 544   \n",
            "14 | post_lstm_add_norm_encoder         | AddNorm                         | 32    \n",
            "15 | static_enrichment                  | GatedResidualNetwork            | 1.4 K \n",
            "16 | multihead_attn                     | InterpretableMultiHeadAttention | 1.1 K \n",
            "17 | post_attn_gate_norm                | GateAddNorm                     | 576   \n",
            "18 | pos_wise_ff                        | GatedResidualNetwork            | 1.1 K \n",
            "19 | pre_output_gate_norm               | GateAddNorm                     | 576   \n",
            "20 | output_layer                       | Linear                          | 119   \n",
            "----------------------------------------------------------------------------------------\n",
            "23.0 K    Trainable params\n",
            "0         Non-trainable params\n",
            "23.0 K    Total params\n",
            "0.092     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.8/dist-packages/pytorch_lightning/trainer/trainer.py:1600: PossibleUserWarning: The number of training batches (30) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
            "  rank_zero_warn(\n",
            "Epoch 0:  97% 30/31 [00:03<00:00,  8.89it/s, loss=87.6, v_num=4, train_loss_step=109.0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 0: 100% 31/31 [00:03<00:00,  8.99it/s, loss=87.6, v_num=4, train_loss_step=109.0, val_loss=152.0]\n",
            "Epoch 1:  97% 30/31 [00:03<00:00,  9.10it/s, loss=75.8, v_num=4, train_loss_step=95.80, val_loss=152.0, train_loss_epoch=104.0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 1: 100% 31/31 [00:03<00:00,  9.20it/s, loss=75.8, v_num=4, train_loss_step=95.80, val_loss=129.0, train_loss_epoch=104.0]\n",
            "Epoch 2:  97% 30/31 [00:03<00:00,  9.30it/s, loss=80.5, v_num=4, train_loss_step=128.0, val_loss=129.0, train_loss_epoch=73.50]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2: 100% 31/31 [00:03<00:00,  9.41it/s, loss=80.5, v_num=4, train_loss_step=128.0, val_loss=128.0, train_loss_epoch=73.50]\n",
            "Epoch 3:  97% 30/31 [00:03<00:00,  9.30it/s, loss=77.5, v_num=4, train_loss_step=36.70, val_loss=128.0, train_loss_epoch=81.00]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 3: 100% 31/31 [00:03<00:00,  9.37it/s, loss=77.5, v_num=4, train_loss_step=36.70, val_loss=125.0, train_loss_epoch=81.00]\n",
            "Epoch 4:  97% 30/31 [00:03<00:00,  9.29it/s, loss=82.6, v_num=4, train_loss_step=125.0, val_loss=125.0, train_loss_epoch=71.30]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 4: 100% 31/31 [00:03<00:00,  9.40it/s, loss=82.6, v_num=4, train_loss_step=125.0, val_loss=122.0, train_loss_epoch=71.30]\n",
            "Epoch 5:  97% 30/31 [00:03<00:00,  8.64it/s, loss=73.7, v_num=4, train_loss_step=67.20, val_loss=122.0, train_loss_epoch=78.90]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 5: 100% 31/31 [00:03<00:00,  8.73it/s, loss=73.7, v_num=4, train_loss_step=67.20, val_loss=122.0, train_loss_epoch=78.90]\n",
            "Epoch 6:  97% 30/31 [00:03<00:00,  9.19it/s, loss=67.3, v_num=4, train_loss_step=58.20, val_loss=122.0, train_loss_epoch=70.50]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 6: 100% 31/31 [00:03<00:00,  9.29it/s, loss=67.3, v_num=4, train_loss_step=58.20, val_loss=118.0, train_loss_epoch=70.50]\n",
            "Epoch 7:  97% 30/31 [00:03<00:00,  7.58it/s, loss=75.6, v_num=4, train_loss_step=83.40, val_loss=118.0, train_loss_epoch=72.80]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 7: 100% 31/31 [00:04<00:00,  7.62it/s, loss=75.6, v_num=4, train_loss_step=83.40, val_loss=127.0, train_loss_epoch=72.80]\n",
            "Epoch 8:  97% 30/31 [00:04<00:00,  7.08it/s, loss=67, v_num=4, train_loss_step=64.40, val_loss=127.0, train_loss_epoch=69.60]  \n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 8: 100% 31/31 [00:04<00:00,  7.19it/s, loss=67, v_num=4, train_loss_step=64.40, val_loss=121.0, train_loss_epoch=69.60]\n",
            "Epoch 9:  97% 30/31 [00:03<00:00,  9.26it/s, loss=73.1, v_num=4, train_loss_step=80.70, val_loss=121.0, train_loss_epoch=68.20]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 9: 100% 31/31 [00:03<00:00,  9.36it/s, loss=73.1, v_num=4, train_loss_step=80.70, val_loss=107.0, train_loss_epoch=68.20]\n",
            "Epoch 10:  97% 30/31 [00:03<00:00,  8.94it/s, loss=52.7, v_num=4, train_loss_step=68.30, val_loss=107.0, train_loss_epoch=71.60]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 10: 100% 31/31 [00:03<00:00,  9.05it/s, loss=52.7, v_num=4, train_loss_step=68.30, val_loss=83.70, train_loss_epoch=71.60]\n",
            "Epoch 11:  97% 30/31 [00:03<00:00,  9.17it/s, loss=52.2, v_num=4, train_loss_step=57.40, val_loss=83.70, train_loss_epoch=54.40]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 11: 100% 31/31 [00:03<00:00,  9.26it/s, loss=52.2, v_num=4, train_loss_step=57.40, val_loss=79.50, train_loss_epoch=54.40]\n",
            "Epoch 12:  97% 30/31 [00:03<00:00,  9.21it/s, loss=53.2, v_num=4, train_loss_step=83.20, val_loss=79.50, train_loss_epoch=50.50]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 12: 100% 31/31 [00:03<00:00,  9.29it/s, loss=53.2, v_num=4, train_loss_step=83.20, val_loss=84.00, train_loss_epoch=50.50]\n",
            "Epoch 13:  97% 30/31 [00:03<00:00,  9.16it/s, loss=51.3, v_num=4, train_loss_step=75.20, val_loss=84.00, train_loss_epoch=54.00]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 13: 100% 31/31 [00:03<00:00,  9.27it/s, loss=51.3, v_num=4, train_loss_step=75.20, val_loss=79.20, train_loss_epoch=54.00]\n",
            "Epoch 14:  97% 30/31 [00:03<00:00,  9.21it/s, loss=45.9, v_num=4, train_loss_step=37.50, val_loss=79.20, train_loss_epoch=51.50]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 14: 100% 31/31 [00:03<00:00,  9.33it/s, loss=45.9, v_num=4, train_loss_step=37.50, val_loss=77.60, train_loss_epoch=51.50]\n",
            "Epoch 15:  97% 30/31 [00:03<00:00,  9.29it/s, loss=43, v_num=4, train_loss_step=25.40, val_loss=77.60, train_loss_epoch=46.50]  \n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 15: 100% 31/31 [00:03<00:00,  9.37it/s, loss=43, v_num=4, train_loss_step=25.40, val_loss=70.80, train_loss_epoch=46.50]\n",
            "Epoch 16:  97% 30/31 [00:03<00:00,  9.16it/s, loss=40.6, v_num=4, train_loss_step=33.10, val_loss=70.80, train_loss_epoch=46.50]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 16: 100% 31/31 [00:03<00:00,  9.27it/s, loss=40.6, v_num=4, train_loss_step=33.10, val_loss=63.40, train_loss_epoch=46.50]\n",
            "Epoch 17:  97% 30/31 [00:03<00:00,  9.25it/s, loss=39.1, v_num=4, train_loss_step=37.70, val_loss=63.40, train_loss_epoch=41.00]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 17: 100% 31/31 [00:03<00:00,  9.34it/s, loss=39.1, v_num=4, train_loss_step=37.70, val_loss=59.30, train_loss_epoch=41.00]\n",
            "Epoch 18:  97% 30/31 [00:03<00:00,  9.18it/s, loss=43.5, v_num=4, train_loss_step=38.20, val_loss=59.30, train_loss_epoch=40.90]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 18: 100% 31/31 [00:03<00:00,  9.26it/s, loss=43.5, v_num=4, train_loss_step=38.20, val_loss=61.50, train_loss_epoch=40.90]\n",
            "Epoch 19:  97% 30/31 [00:03<00:00,  9.25it/s, loss=40.2, v_num=4, train_loss_step=39.40, val_loss=61.50, train_loss_epoch=41.50]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 19: 100% 31/31 [00:03<00:00,  9.35it/s, loss=40.2, v_num=4, train_loss_step=39.40, val_loss=61.50, train_loss_epoch=41.50]\n",
            "Epoch 20:  97% 30/31 [00:03<00:00,  9.33it/s, loss=43.7, v_num=4, train_loss_step=64.00, val_loss=61.50, train_loss_epoch=41.00]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 20: 100% 31/31 [00:03<00:00,  9.43it/s, loss=43.7, v_num=4, train_loss_step=64.00, val_loss=67.60, train_loss_epoch=41.00]\n",
            "Epoch 21:  97% 30/31 [00:03<00:00,  9.37it/s, loss=47.2, v_num=4, train_loss_step=95.30, val_loss=67.60, train_loss_epoch=42.20]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 21: 100% 31/31 [00:03<00:00,  9.48it/s, loss=47.2, v_num=4, train_loss_step=95.30, val_loss=55.80, train_loss_epoch=42.20]\n",
            "Epoch 22:  97% 30/31 [00:03<00:00,  9.33it/s, loss=38.1, v_num=4, train_loss_step=19.40, val_loss=55.80, train_loss_epoch=45.00]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 22: 100% 31/31 [00:03<00:00,  9.44it/s, loss=38.1, v_num=4, train_loss_step=19.40, val_loss=61.10, train_loss_epoch=45.00]\n",
            "Epoch 23:  97% 30/31 [00:03<00:00,  9.25it/s, loss=38.1, v_num=4, train_loss_step=33.70, val_loss=61.10, train_loss_epoch=38.40]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 23: 100% 31/31 [00:03<00:00,  9.35it/s, loss=38.1, v_num=4, train_loss_step=33.70, val_loss=59.90, train_loss_epoch=38.40]\n",
            "Epoch 24:  97% 30/31 [00:03<00:00,  9.28it/s, loss=38.9, v_num=4, train_loss_step=34.90, val_loss=59.90, train_loss_epoch=37.70]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 24: 100% 31/31 [00:03<00:00,  9.40it/s, loss=38.9, v_num=4, train_loss_step=34.90, val_loss=60.10, train_loss_epoch=37.70]\n",
            "Epoch 25:  97% 30/31 [00:03<00:00,  9.37it/s, loss=37.4, v_num=4, train_loss_step=52.50, val_loss=60.10, train_loss_epoch=40.80]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 25: 100% 31/31 [00:03<00:00,  9.48it/s, loss=37.4, v_num=4, train_loss_step=52.50, val_loss=56.30, train_loss_epoch=40.80]\n",
            "Epoch 26:  97% 30/31 [00:03<00:00,  9.45it/s, loss=39, v_num=4, train_loss_step=42.70, val_loss=56.30, train_loss_epoch=37.50]  \n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 26: 100% 31/31 [00:03<00:00,  9.56it/s, loss=39, v_num=4, train_loss_step=42.70, val_loss=56.00, train_loss_epoch=37.50]\n",
            "Epoch 27:  97% 30/31 [00:03<00:00,  9.39it/s, loss=35.3, v_num=4, train_loss_step=34.90, val_loss=56.00, train_loss_epoch=40.50]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 27: 100% 31/31 [00:03<00:00,  9.49it/s, loss=35.3, v_num=4, train_loss_step=34.90, val_loss=64.70, train_loss_epoch=40.50]\n",
            "Epoch 28:  97% 30/31 [00:03<00:00,  9.24it/s, loss=38.9, v_num=4, train_loss_step=44.00, val_loss=64.70, train_loss_epoch=35.50]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 28: 100% 31/31 [00:03<00:00,  9.34it/s, loss=38.9, v_num=4, train_loss_step=44.00, val_loss=58.70, train_loss_epoch=35.50]\n",
            "Epoch 29:  97% 30/31 [00:03<00:00,  9.42it/s, loss=39.5, v_num=4, train_loss_step=45.70, val_loss=58.70, train_loss_epoch=39.20]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 29: 100% 31/31 [00:03<00:00,  9.50it/s, loss=39.5, v_num=4, train_loss_step=45.70, val_loss=60.40, train_loss_epoch=39.20]\n",
            "Epoch 30:  97% 30/31 [00:03<00:00,  9.19it/s, loss=38.3, v_num=4, train_loss_step=41.30, val_loss=60.40, train_loss_epoch=37.50]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 30: 100% 31/31 [00:03<00:00,  9.29it/s, loss=38.3, v_num=4, train_loss_step=41.30, val_loss=58.40, train_loss_epoch=37.50]\n",
            "Epoch 31:  97% 30/31 [00:03<00:00,  9.13it/s, loss=37.4, v_num=4, train_loss_step=33.60, val_loss=58.40, train_loss_epoch=40.80]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 31: 100% 31/31 [00:03<00:00,  9.23it/s, loss=37.4, v_num=4, train_loss_step=33.60, val_loss=54.50, train_loss_epoch=40.80]\n",
            "Epoch 32:  97% 30/31 [00:03<00:00,  9.42it/s, loss=31.3, v_num=4, train_loss_step=27.40, val_loss=54.50, train_loss_epoch=39.60]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 32: 100% 31/31 [00:03<00:00,  9.52it/s, loss=31.3, v_num=4, train_loss_step=27.40, val_loss=53.00, train_loss_epoch=39.60]\n",
            "Epoch 33:  97% 30/31 [00:03<00:00,  9.24it/s, loss=38.1, v_num=4, train_loss_step=63.60, val_loss=53.00, train_loss_epoch=34.90]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 33: 100% 31/31 [00:03<00:00,  9.35it/s, loss=38.1, v_num=4, train_loss_step=63.60, val_loss=56.70, train_loss_epoch=34.90]\n",
            "Epoch 34:  97% 30/31 [00:03<00:00,  9.32it/s, loss=34.2, v_num=4, train_loss_step=30.70, val_loss=56.70, train_loss_epoch=35.40]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 34: 100% 31/31 [00:03<00:00,  9.42it/s, loss=34.2, v_num=4, train_loss_step=30.70, val_loss=62.50, train_loss_epoch=35.40]\n",
            "Epoch 35:  97% 30/31 [00:03<00:00,  9.48it/s, loss=37.6, v_num=4, train_loss_step=20.70, val_loss=62.50, train_loss_epoch=34.10]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 35: 100% 31/31 [00:03<00:00,  9.59it/s, loss=37.6, v_num=4, train_loss_step=20.70, val_loss=50.50, train_loss_epoch=34.10]\n",
            "Epoch 36:  97% 30/31 [00:03<00:00,  9.34it/s, loss=38, v_num=4, train_loss_step=33.60, val_loss=50.50, train_loss_epoch=36.60]  \n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 36: 100% 31/31 [00:03<00:00,  9.45it/s, loss=38, v_num=4, train_loss_step=33.60, val_loss=68.30, train_loss_epoch=36.60]\n",
            "Epoch 37:  97% 30/31 [00:03<00:00,  9.23it/s, loss=37.2, v_num=4, train_loss_step=21.20, val_loss=68.30, train_loss_epoch=36.30]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 37: 100% 31/31 [00:03<00:00,  9.34it/s, loss=37.2, v_num=4, train_loss_step=21.20, val_loss=53.50, train_loss_epoch=36.30]\n",
            "Epoch 38:  97% 30/31 [00:03<00:00,  9.41it/s, loss=37.7, v_num=4, train_loss_step=19.60, val_loss=53.50, train_loss_epoch=38.50]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 38: 100% 31/31 [00:03<00:00,  9.51it/s, loss=37.7, v_num=4, train_loss_step=19.60, val_loss=50.50, train_loss_epoch=38.50]\n",
            "Epoch 39:  97% 30/31 [00:03<00:00,  9.41it/s, loss=33.6, v_num=4, train_loss_step=35.50, val_loss=50.50, train_loss_epoch=36.30]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 39: 100% 31/31 [00:03<00:00,  9.51it/s, loss=33.6, v_num=4, train_loss_step=35.50, val_loss=62.10, train_loss_epoch=36.30]\n",
            "Epoch 40:  97% 30/31 [00:03<00:00,  9.31it/s, loss=31, v_num=4, train_loss_step=34.80, val_loss=62.10, train_loss_epoch=33.30]  \n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 40: 100% 31/31 [00:03<00:00,  9.40it/s, loss=31, v_num=4, train_loss_step=34.80, val_loss=52.10, train_loss_epoch=33.30]\n",
            "Epoch 41:  97% 30/31 [00:03<00:00,  9.29it/s, loss=35.6, v_num=4, train_loss_step=36.00, val_loss=52.10, train_loss_epoch=35.20]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 41: 100% 31/31 [00:03<00:00,  9.40it/s, loss=35.6, v_num=4, train_loss_step=36.00, val_loss=51.70, train_loss_epoch=35.20]\n",
            "Epoch 42:  97% 30/31 [00:03<00:00,  9.36it/s, loss=29.9, v_num=4, train_loss_step=21.70, val_loss=51.70, train_loss_epoch=35.80]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 42: 100% 31/31 [00:03<00:00,  9.45it/s, loss=29.9, v_num=4, train_loss_step=21.70, val_loss=55.30, train_loss_epoch=35.80]\n",
            "Epoch 43:  97% 30/31 [00:03<00:00,  9.29it/s, loss=32.1, v_num=4, train_loss_step=34.90, val_loss=55.30, train_loss_epoch=31.80]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 43: 100% 31/31 [00:03<00:00,  9.40it/s, loss=32.1, v_num=4, train_loss_step=34.90, val_loss=54.60, train_loss_epoch=31.80]\n",
            "Epoch 44:  97% 30/31 [00:03<00:00,  9.45it/s, loss=31.6, v_num=4, train_loss_step=28.60, val_loss=54.60, train_loss_epoch=33.60]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 44: 100% 31/31 [00:03<00:00,  9.54it/s, loss=31.6, v_num=4, train_loss_step=28.60, val_loss=53.30, train_loss_epoch=33.60]\n",
            "Epoch 45:  97% 30/31 [00:03<00:00,  9.43it/s, loss=35.1, v_num=4, train_loss_step=36.90, val_loss=53.30, train_loss_epoch=32.40]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 45: 100% 31/31 [00:03<00:00,  9.54it/s, loss=35.1, v_num=4, train_loss_step=36.90, val_loss=53.30, train_loss_epoch=32.40]\n",
            "Epoch 46:  97% 30/31 [00:03<00:00,  9.33it/s, loss=31.9, v_num=4, train_loss_step=39.20, val_loss=53.30, train_loss_epoch=34.20]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 46: 100% 31/31 [00:03<00:00,  9.44it/s, loss=31.9, v_num=4, train_loss_step=39.20, val_loss=52.80, train_loss_epoch=34.20]\n",
            "Epoch 47:  97% 30/31 [00:03<00:00,  9.26it/s, loss=30.1, v_num=4, train_loss_step=21.50, val_loss=52.80, train_loss_epoch=32.00]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 47: 100% 31/31 [00:03<00:00,  9.37it/s, loss=30.1, v_num=4, train_loss_step=21.50, val_loss=53.00, train_loss_epoch=32.00]\n",
            "Epoch 48:  97% 30/31 [00:03<00:00,  9.34it/s, loss=34, v_num=4, train_loss_step=40.50, val_loss=53.00, train_loss_epoch=31.70]  \n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 48: 100% 31/31 [00:03<00:00,  9.46it/s, loss=34, v_num=4, train_loss_step=40.50, val_loss=56.20, train_loss_epoch=31.70]\n",
            "Epoch 49:  97% 30/31 [00:03<00:00,  9.36it/s, loss=30.8, v_num=4, train_loss_step=23.70, val_loss=56.20, train_loss_epoch=32.20]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 49: 100% 31/31 [00:03<00:00,  9.47it/s, loss=30.8, v_num=4, train_loss_step=23.70, val_loss=52.50, train_loss_epoch=32.20]\n",
            "Epoch 50:  97% 30/31 [00:03<00:00,  9.46it/s, loss=29.8, v_num=4, train_loss_step=30.90, val_loss=52.50, train_loss_epoch=31.30]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 50: 100% 31/31 [00:03<00:00,  9.57it/s, loss=29.8, v_num=4, train_loss_step=30.90, val_loss=51.20, train_loss_epoch=31.30]\n",
            "Epoch 51:  97% 30/31 [00:03<00:00,  9.28it/s, loss=29.1, v_num=4, train_loss_step=27.80, val_loss=51.20, train_loss_epoch=30.60]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 51: 100% 31/31 [00:03<00:00,  9.37it/s, loss=29.1, v_num=4, train_loss_step=27.80, val_loss=50.90, train_loss_epoch=30.60]\n",
            "Epoch 52:  97% 30/31 [00:03<00:00,  9.42it/s, loss=29.1, v_num=4, train_loss_step=23.00, val_loss=50.90, train_loss_epoch=29.00]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 52: 100% 31/31 [00:03<00:00,  9.54it/s, loss=29.1, v_num=4, train_loss_step=23.00, val_loss=51.40, train_loss_epoch=29.00]\n",
            "Epoch 53:  97% 30/31 [00:03<00:00,  9.44it/s, loss=31.4, v_num=4, train_loss_step=24.60, val_loss=51.40, train_loss_epoch=29.90]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 53: 100% 31/31 [00:03<00:00,  9.55it/s, loss=31.4, v_num=4, train_loss_step=24.60, val_loss=53.70, train_loss_epoch=29.90]\n",
            "Epoch 54:  97% 30/31 [00:03<00:00,  9.35it/s, loss=30.5, v_num=4, train_loss_step=21.00, val_loss=53.70, train_loss_epoch=30.30]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 54: 100% 31/31 [00:03<00:00,  9.46it/s, loss=30.5, v_num=4, train_loss_step=21.00, val_loss=56.20, train_loss_epoch=30.30]\n",
            "Epoch 55:  97% 30/31 [00:03<00:00,  9.15it/s, loss=31.6, v_num=4, train_loss_step=34.00, val_loss=56.20, train_loss_epoch=29.70]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 55: 100% 31/31 [00:03<00:00,  9.26it/s, loss=31.6, v_num=4, train_loss_step=34.00, val_loss=56.60, train_loss_epoch=29.70]\n",
            "Epoch 56:  97% 30/31 [00:03<00:00,  9.36it/s, loss=31.3, v_num=4, train_loss_step=30.00, val_loss=56.60, train_loss_epoch=33.00]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 56: 100% 31/31 [00:03<00:00,  9.47it/s, loss=31.3, v_num=4, train_loss_step=30.00, val_loss=58.20, train_loss_epoch=33.00]\n",
            "Epoch 57:  97% 30/31 [00:03<00:00,  9.35it/s, loss=32, v_num=4, train_loss_step=24.00, val_loss=58.20, train_loss_epoch=30.50]  \n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 57: 100% 31/31 [00:03<00:00,  9.46it/s, loss=32, v_num=4, train_loss_step=24.00, val_loss=57.30, train_loss_epoch=30.50]\n",
            "Epoch 58:  97% 30/31 [00:03<00:00,  9.23it/s, loss=28.5, v_num=4, train_loss_step=22.90, val_loss=57.30, train_loss_epoch=31.30]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 58: 100% 31/31 [00:03<00:00,  9.34it/s, loss=28.5, v_num=4, train_loss_step=22.90, val_loss=54.10, train_loss_epoch=31.30]\n",
            "Epoch 59:  97% 30/31 [00:03<00:00,  9.41it/s, loss=30.5, v_num=4, train_loss_step=25.10, val_loss=54.10, train_loss_epoch=29.90]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 59: 100% 31/31 [00:03<00:00,  9.52it/s, loss=30.5, v_num=4, train_loss_step=25.10, val_loss=53.60, train_loss_epoch=29.90]\n",
            "Epoch 60:  97% 30/31 [00:03<00:00,  9.33it/s, loss=30.3, v_num=4, train_loss_step=26.90, val_loss=53.60, train_loss_epoch=32.00]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 60: 100% 31/31 [00:03<00:00,  9.44it/s, loss=30.3, v_num=4, train_loss_step=26.90, val_loss=52.30, train_loss_epoch=32.00]\n",
            "Epoch 61:  97% 30/31 [00:03<00:00,  9.26it/s, loss=29, v_num=4, train_loss_step=29.30, val_loss=52.30, train_loss_epoch=30.80]  \n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 61: 100% 31/31 [00:03<00:00,  9.36it/s, loss=29, v_num=4, train_loss_step=29.30, val_loss=53.20, train_loss_epoch=30.80]\n",
            "Epoch 62:  97% 30/31 [00:03<00:00,  9.30it/s, loss=30.1, v_num=4, train_loss_step=23.60, val_loss=53.20, train_loss_epoch=29.50]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 62: 100% 31/31 [00:03<00:00,  9.41it/s, loss=30.1, v_num=4, train_loss_step=23.60, val_loss=54.80, train_loss_epoch=29.50]\n",
            "Epoch 63:  97% 30/31 [00:03<00:00,  9.41it/s, loss=30.8, v_num=4, train_loss_step=17.60, val_loss=54.80, train_loss_epoch=30.30]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 63: 100% 31/31 [00:03<00:00,  9.52it/s, loss=30.8, v_num=4, train_loss_step=17.60, val_loss=55.50, train_loss_epoch=30.30]\n",
            "Epoch 64:  97% 30/31 [00:03<00:00,  9.22it/s, loss=31.8, v_num=4, train_loss_step=39.40, val_loss=55.50, train_loss_epoch=28.30]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 64: 100% 31/31 [00:03<00:00,  9.32it/s, loss=31.8, v_num=4, train_loss_step=39.40, val_loss=55.20, train_loss_epoch=28.30]\n",
            "Epoch 65:  97% 30/31 [00:03<00:00,  9.21it/s, loss=27.3, v_num=4, train_loss_step=24.10, val_loss=55.20, train_loss_epoch=29.90]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 65: 100% 31/31 [00:03<00:00,  9.29it/s, loss=27.3, v_num=4, train_loss_step=24.10, val_loss=54.10, train_loss_epoch=29.90]\n",
            "Epoch 66:  97% 30/31 [00:03<00:00,  9.34it/s, loss=31.2, v_num=4, train_loss_step=30.70, val_loss=54.10, train_loss_epoch=27.70]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 66: 100% 31/31 [00:03<00:00,  9.44it/s, loss=31.2, v_num=4, train_loss_step=30.70, val_loss=54.90, train_loss_epoch=27.70]\n",
            "Epoch 67:  97% 30/31 [00:03<00:00,  9.24it/s, loss=29.6, v_num=4, train_loss_step=29.20, val_loss=54.90, train_loss_epoch=30.20]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 67: 100% 31/31 [00:03<00:00,  9.36it/s, loss=29.6, v_num=4, train_loss_step=29.20, val_loss=55.80, train_loss_epoch=30.20]\n",
            "Epoch 68:  97% 30/31 [00:03<00:00,  9.24it/s, loss=28.9, v_num=4, train_loss_step=41.00, val_loss=55.80, train_loss_epoch=30.10]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 68: 100% 31/31 [00:03<00:00,  9.35it/s, loss=28.9, v_num=4, train_loss_step=41.00, val_loss=55.50, train_loss_epoch=30.10]\n",
            "Epoch 69:  97% 30/31 [00:03<00:00,  9.29it/s, loss=27.3, v_num=4, train_loss_step=27.30, val_loss=55.50, train_loss_epoch=29.40]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 69: 100% 31/31 [00:03<00:00,  9.39it/s, loss=27.3, v_num=4, train_loss_step=27.30, val_loss=56.00, train_loss_epoch=29.40]\n",
            "Epoch 70:  97% 30/31 [00:03<00:00,  9.36it/s, loss=25.4, v_num=4, train_loss_step=19.60, val_loss=56.00, train_loss_epoch=28.00]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 70: 100% 31/31 [00:03<00:00,  9.47it/s, loss=25.4, v_num=4, train_loss_step=19.60, val_loss=57.30, train_loss_epoch=28.00]\n",
            "Epoch 71:  97% 30/31 [00:03<00:00,  9.24it/s, loss=30, v_num=4, train_loss_step=21.70, val_loss=57.30, train_loss_epoch=26.00]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 71: 100% 31/31 [00:03<00:00,  9.35it/s, loss=30, v_num=4, train_loss_step=21.70, val_loss=56.70, train_loss_epoch=26.00]\n",
            "Epoch 72:  97% 30/31 [00:03<00:00,  9.41it/s, loss=29.6, v_num=4, train_loss_step=40.10, val_loss=56.70, train_loss_epoch=30.30]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 72: 100% 31/31 [00:03<00:00,  9.51it/s, loss=29.6, v_num=4, train_loss_step=40.10, val_loss=55.60, train_loss_epoch=30.30]\n",
            "Epoch 73:  97% 30/31 [00:03<00:00,  9.26it/s, loss=27.9, v_num=4, train_loss_step=20.90, val_loss=55.60, train_loss_epoch=30.90]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 73: 100% 31/31 [00:03<00:00,  9.36it/s, loss=27.9, v_num=4, train_loss_step=20.90, val_loss=55.40, train_loss_epoch=30.90]\n",
            "Epoch 74:  97% 30/31 [00:03<00:00,  9.03it/s, loss=30.2, v_num=4, train_loss_step=31.10, val_loss=55.40, train_loss_epoch=30.80]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 74: 100% 31/31 [00:03<00:00,  9.00it/s, loss=30.2, v_num=4, train_loss_step=31.10, val_loss=55.50, train_loss_epoch=30.80]\n",
            "Epoch 75:  97% 30/31 [00:04<00:00,  6.09it/s, loss=30.1, v_num=4, train_loss_step=45.40, val_loss=55.50, train_loss_epoch=30.40]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 75: 100% 31/31 [00:04<00:00,  6.20it/s, loss=30.1, v_num=4, train_loss_step=45.40, val_loss=56.10, train_loss_epoch=30.40]\n",
            "Epoch 76:  97% 30/31 [00:03<00:00,  9.22it/s, loss=29.7, v_num=4, train_loss_step=25.30, val_loss=56.10, train_loss_epoch=28.40]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 76: 100% 31/31 [00:03<00:00,  9.33it/s, loss=29.7, v_num=4, train_loss_step=25.30, val_loss=55.90, train_loss_epoch=28.40]\n",
            "Epoch 77:  97% 30/31 [00:03<00:00,  9.38it/s, loss=26.5, v_num=4, train_loss_step=21.30, val_loss=55.90, train_loss_epoch=29.40]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 77: 100% 31/31 [00:03<00:00,  9.45it/s, loss=26.5, v_num=4, train_loss_step=21.30, val_loss=56.10, train_loss_epoch=29.40]\n",
            "Epoch 78:  97% 30/31 [00:03<00:00,  9.28it/s, loss=28.8, v_num=4, train_loss_step=17.80, val_loss=56.10, train_loss_epoch=27.90]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 78: 100% 31/31 [00:03<00:00,  9.40it/s, loss=28.8, v_num=4, train_loss_step=17.80, val_loss=56.00, train_loss_epoch=27.90]\n",
            "Epoch 79:  97% 30/31 [00:03<00:00,  9.44it/s, loss=31.8, v_num=4, train_loss_step=31.90, val_loss=56.00, train_loss_epoch=26.90]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 79: 100% 31/31 [00:03<00:00,  9.54it/s, loss=31.8, v_num=4, train_loss_step=31.90, val_loss=55.90, train_loss_epoch=26.90]\n",
            "Epoch 80:  97% 30/31 [00:03<00:00,  9.37it/s, loss=31.2, v_num=4, train_loss_step=32.20, val_loss=55.90, train_loss_epoch=30.60]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 80: 100% 31/31 [00:03<00:00,  9.48it/s, loss=31.2, v_num=4, train_loss_step=32.20, val_loss=55.70, train_loss_epoch=30.60]\n",
            "Epoch 81:  97% 30/31 [00:03<00:00,  9.41it/s, loss=26, v_num=4, train_loss_step=22.50, val_loss=55.70, train_loss_epoch=30.10]  \n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 81: 100% 31/31 [00:03<00:00,  9.50it/s, loss=26, v_num=4, train_loss_step=22.50, val_loss=55.90, train_loss_epoch=30.10]\n",
            "Epoch 82:  97% 30/31 [00:03<00:00,  9.26it/s, loss=27.1, v_num=4, train_loss_step=23.80, val_loss=55.90, train_loss_epoch=28.90]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 82: 100% 31/31 [00:03<00:00,  9.37it/s, loss=27.1, v_num=4, train_loss_step=23.80, val_loss=55.90, train_loss_epoch=28.90]\n",
            "Epoch 83:  97% 30/31 [00:03<00:00,  9.44it/s, loss=26.4, v_num=4, train_loss_step=18.70, val_loss=55.90, train_loss_epoch=26.90]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 83: 100% 31/31 [00:03<00:00,  9.55it/s, loss=26.4, v_num=4, train_loss_step=18.70, val_loss=56.40, train_loss_epoch=26.90]\n",
            "Epoch 84:  97% 30/31 [00:03<00:00,  9.44it/s, loss=29.1, v_num=4, train_loss_step=19.40, val_loss=56.40, train_loss_epoch=26.70]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 84: 100% 31/31 [00:03<00:00,  9.55it/s, loss=29.1, v_num=4, train_loss_step=19.40, val_loss=56.60, train_loss_epoch=26.70]\n",
            "Epoch 85:  97% 30/31 [00:03<00:00,  9.36it/s, loss=26.9, v_num=4, train_loss_step=21.90, val_loss=56.60, train_loss_epoch=27.70]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 85: 100% 31/31 [00:03<00:00,  9.46it/s, loss=26.9, v_num=4, train_loss_step=21.90, val_loss=56.60, train_loss_epoch=27.70]\n",
            "Epoch 86:  97% 30/31 [00:03<00:00,  9.31it/s, loss=27.8, v_num=4, train_loss_step=24.70, val_loss=56.60, train_loss_epoch=30.30]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 86: 100% 31/31 [00:03<00:00,  9.41it/s, loss=27.8, v_num=4, train_loss_step=24.70, val_loss=56.50, train_loss_epoch=30.30]\n",
            "Epoch 87:  97% 30/31 [00:03<00:00,  9.25it/s, loss=28, v_num=4, train_loss_step=41.90, val_loss=56.50, train_loss_epoch=27.00]  \n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 87: 100% 31/31 [00:03<00:00,  9.36it/s, loss=28, v_num=4, train_loss_step=41.90, val_loss=56.50, train_loss_epoch=27.00]\n",
            "Epoch 88:  97% 30/31 [00:03<00:00,  9.28it/s, loss=26.9, v_num=4, train_loss_step=41.30, val_loss=56.50, train_loss_epoch=29.60]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 88: 100% 31/31 [00:03<00:00,  9.39it/s, loss=26.9, v_num=4, train_loss_step=41.30, val_loss=56.50, train_loss_epoch=29.60]\n",
            "Epoch 89:  97% 30/31 [00:03<00:00,  9.29it/s, loss=28.6, v_num=4, train_loss_step=21.70, val_loss=56.50, train_loss_epoch=27.40]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 89: 100% 31/31 [00:03<00:00,  9.39it/s, loss=28.6, v_num=4, train_loss_step=21.70, val_loss=56.50, train_loss_epoch=27.40]\n",
            "Epoch 90:  97% 30/31 [00:03<00:00,  9.31it/s, loss=31.9, v_num=4, train_loss_step=30.90, val_loss=56.50, train_loss_epoch=27.40]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 90: 100% 31/31 [00:03<00:00,  9.43it/s, loss=31.9, v_num=4, train_loss_step=30.90, val_loss=56.40, train_loss_epoch=27.40]\n",
            "Epoch 91:  97% 30/31 [00:03<00:00,  9.28it/s, loss=29.8, v_num=4, train_loss_step=33.70, val_loss=56.40, train_loss_epoch=30.40]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 91: 100% 31/31 [00:03<00:00,  9.40it/s, loss=29.8, v_num=4, train_loss_step=33.70, val_loss=56.30, train_loss_epoch=30.40]\n",
            "Epoch 92:  97% 30/31 [00:03<00:00,  9.44it/s, loss=29.4, v_num=4, train_loss_step=35.90, val_loss=56.30, train_loss_epoch=29.30]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 92: 100% 31/31 [00:03<00:00,  9.56it/s, loss=29.4, v_num=4, train_loss_step=35.90, val_loss=56.30, train_loss_epoch=29.30]\n",
            "Epoch 93:  97% 30/31 [00:03<00:00,  9.44it/s, loss=29.4, v_num=4, train_loss_step=43.40, val_loss=56.30, train_loss_epoch=31.30]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 93: 100% 31/31 [00:03<00:00,  9.55it/s, loss=29.4, v_num=4, train_loss_step=43.40, val_loss=56.40, train_loss_epoch=31.30]\n",
            "Epoch 94:  97% 30/31 [00:03<00:00,  9.44it/s, loss=26, v_num=4, train_loss_step=28.60, val_loss=56.40, train_loss_epoch=30.00]  \n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 94: 100% 31/31 [00:03<00:00,  9.54it/s, loss=26, v_num=4, train_loss_step=28.60, val_loss=56.40, train_loss_epoch=30.00]\n",
            "Epoch 95:  97% 30/31 [00:03<00:00,  9.42it/s, loss=28.1, v_num=4, train_loss_step=17.30, val_loss=56.40, train_loss_epoch=27.60]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 95: 100% 31/31 [00:03<00:00,  9.54it/s, loss=28.1, v_num=4, train_loss_step=17.30, val_loss=56.60, train_loss_epoch=27.60]\n",
            "Epoch 95: 100% 31/31 [00:03<00:00,  9.35it/s, loss=28.1, v_num=4, train_loss_step=17.30, val_loss=56.60, train_loss_epoch=28.50]\n",
            "16123\n",
            "3745\n",
            "267\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.8/dist-packages/pytorch_lightning/utilities/parsing.py:262: UserWarning: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
            "  rank_zero_warn(\n",
            "/usr/local/lib/python3.8/dist-packages/pytorch_lightning/utilities/parsing.py:262: UserWarning: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.\n",
            "  rank_zero_warn(\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "   | Name                               | Type                            | Params\n",
            "----------------------------------------------------------------------------------------\n",
            "0  | loss                               | QuantileLoss                    | 0     \n",
            "1  | logging_metrics                    | ModuleList                      | 0     \n",
            "2  | input_embeddings                   | MultiEmbedding                  | 288   \n",
            "3  | prescalers                         | ModuleDict                      | 176   \n",
            "4  | static_variable_selection          | VariableSelectionNetwork        | 2.6 K \n",
            "5  | encoder_variable_selection         | VariableSelectionNetwork        | 4.6 K \n",
            "6  | decoder_variable_selection         | VariableSelectionNetwork        | 1.3 K \n",
            "7  | static_context_variable_selection  | GatedResidualNetwork            | 1.1 K \n",
            "8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 1.1 K \n",
            "9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 1.1 K \n",
            "10 | static_context_enrichment          | GatedResidualNetwork            | 1.1 K \n",
            "11 | lstm_encoder                       | LSTM                            | 2.2 K \n",
            "12 | lstm_decoder                       | LSTM                            | 2.2 K \n",
            "13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 544   \n",
            "14 | post_lstm_add_norm_encoder         | AddNorm                         | 32    \n",
            "15 | static_enrichment                  | GatedResidualNetwork            | 1.4 K \n",
            "16 | multihead_attn                     | InterpretableMultiHeadAttention | 1.1 K \n",
            "17 | post_attn_gate_norm                | GateAddNorm                     | 576   \n",
            "18 | pos_wise_ff                        | GatedResidualNetwork            | 1.1 K \n",
            "19 | pre_output_gate_norm               | GateAddNorm                     | 576   \n",
            "20 | output_layer                       | Linear                          | 119   \n",
            "----------------------------------------------------------------------------------------\n",
            "23.0 K    Trainable params\n",
            "0         Non-trainable params\n",
            "23.0 K    Total params\n",
            "0.092     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.8/dist-packages/pytorch_lightning/trainer/trainer.py:1600: PossibleUserWarning: The number of training batches (30) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
            "  rank_zero_warn(\n",
            "Epoch 0:  97% 30/31 [00:03<00:00,  9.32it/s, loss=67.4, v_num=5, train_loss_step=43.90]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 0: 100% 31/31 [00:03<00:00,  9.43it/s, loss=67.4, v_num=5, train_loss_step=43.90, val_loss=142.0]\n",
            "Epoch 1:  97% 30/31 [00:03<00:00,  9.35it/s, loss=51.1, v_num=5, train_loss_step=32.20, val_loss=142.0, train_loss_epoch=82.20]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 1: 100% 31/31 [00:03<00:00,  9.46it/s, loss=51.1, v_num=5, train_loss_step=32.20, val_loss=122.0, train_loss_epoch=82.20]\n",
            "Epoch 2:  97% 30/31 [00:03<00:00,  9.40it/s, loss=55.7, v_num=5, train_loss_step=58.60, val_loss=122.0, train_loss_epoch=51.60]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2: 100% 31/31 [00:03<00:00,  9.52it/s, loss=55.7, v_num=5, train_loss_step=58.60, val_loss=93.30, train_loss_epoch=51.60]\n",
            "Epoch 3:  97% 30/31 [00:03<00:00,  9.21it/s, loss=50.5, v_num=5, train_loss_step=74.00, val_loss=93.30, train_loss_epoch=57.50]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 3: 100% 31/31 [00:03<00:00,  9.29it/s, loss=50.5, v_num=5, train_loss_step=74.00, val_loss=116.0, train_loss_epoch=57.50]\n",
            "Epoch 4:  97% 30/31 [00:03<00:00,  9.26it/s, loss=49.4, v_num=5, train_loss_step=27.90, val_loss=116.0, train_loss_epoch=53.90]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 4: 100% 31/31 [00:03<00:00,  9.37it/s, loss=49.4, v_num=5, train_loss_step=27.90, val_loss=80.70, train_loss_epoch=53.90]\n",
            "Epoch 5:  97% 30/31 [00:03<00:00,  9.27it/s, loss=49.4, v_num=5, train_loss_step=35.90, val_loss=80.70, train_loss_epoch=48.10]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 5: 100% 31/31 [00:03<00:00,  9.36it/s, loss=49.4, v_num=5, train_loss_step=35.90, val_loss=80.70, train_loss_epoch=48.10]\n",
            "Epoch 6:  97% 30/31 [00:03<00:00,  9.36it/s, loss=47.1, v_num=5, train_loss_step=36.80, val_loss=80.70, train_loss_epoch=49.30]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 6: 100% 31/31 [00:03<00:00,  9.48it/s, loss=47.1, v_num=5, train_loss_step=36.80, val_loss=73.80, train_loss_epoch=49.30]\n",
            "Epoch 7:  97% 30/31 [00:03<00:00,  9.32it/s, loss=45.4, v_num=5, train_loss_step=61.90, val_loss=73.80, train_loss_epoch=48.30]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 7: 100% 31/31 [00:03<00:00,  9.43it/s, loss=45.4, v_num=5, train_loss_step=61.90, val_loss=101.0, train_loss_epoch=48.30]\n",
            "Epoch 8:  97% 30/31 [00:03<00:00,  9.04it/s, loss=51.5, v_num=5, train_loss_step=35.60, val_loss=101.0, train_loss_epoch=46.60]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 8: 100% 31/31 [00:03<00:00,  9.14it/s, loss=51.5, v_num=5, train_loss_step=35.60, val_loss=70.80, train_loss_epoch=46.60]\n",
            "Epoch 9:  97% 30/31 [00:03<00:00,  9.29it/s, loss=45, v_num=5, train_loss_step=30.90, val_loss=70.80, train_loss_epoch=49.10]  \n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 9: 100% 31/31 [00:03<00:00,  9.40it/s, loss=45, v_num=5, train_loss_step=30.90, val_loss=78.30, train_loss_epoch=49.10]\n",
            "Epoch 10:  97% 30/31 [00:03<00:00,  9.32it/s, loss=43.9, v_num=5, train_loss_step=23.90, val_loss=78.30, train_loss_epoch=44.60]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 10: 100% 31/31 [00:03<00:00,  9.42it/s, loss=43.9, v_num=5, train_loss_step=23.90, val_loss=72.50, train_loss_epoch=44.60]\n",
            "Epoch 11:  97% 30/31 [00:03<00:00,  9.38it/s, loss=41.7, v_num=5, train_loss_step=30.50, val_loss=72.50, train_loss_epoch=44.10]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 11: 100% 31/31 [00:03<00:00,  9.49it/s, loss=41.7, v_num=5, train_loss_step=30.50, val_loss=71.30, train_loss_epoch=44.10]\n",
            "Epoch 12:  55% 17/31 [00:01<00:01,  9.49it/s, loss=38.7, v_num=5, train_loss_step=22.20, val_loss=71.30, train_loss_epoch=43.70]/usr/local/lib/python3.8/dist-packages/pytorch_lightning/trainer/call.py:48: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
            "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n",
            "7969\n",
            "2301\n",
            "59\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.8/dist-packages/pytorch_lightning/utilities/parsing.py:262: UserWarning: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
            "  rank_zero_warn(\n",
            "/usr/local/lib/python3.8/dist-packages/pytorch_lightning/utilities/parsing.py:262: UserWarning: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.\n",
            "  rank_zero_warn(\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "   | Name                               | Type                            | Params\n",
            "----------------------------------------------------------------------------------------\n",
            "0  | loss                               | QuantileLoss                    | 0     \n",
            "1  | logging_metrics                    | ModuleList                      | 0     \n",
            "2  | input_embeddings                   | MultiEmbedding                  | 288   \n",
            "3  | prescalers                         | ModuleDict                      | 176   \n",
            "4  | static_variable_selection          | VariableSelectionNetwork        | 2.6 K \n",
            "5  | encoder_variable_selection         | VariableSelectionNetwork        | 4.6 K \n",
            "6  | decoder_variable_selection         | VariableSelectionNetwork        | 1.3 K \n",
            "7  | static_context_variable_selection  | GatedResidualNetwork            | 1.1 K \n",
            "8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 1.1 K \n",
            "9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 1.1 K \n",
            "10 | static_context_enrichment          | GatedResidualNetwork            | 1.1 K \n",
            "11 | lstm_encoder                       | LSTM                            | 2.2 K \n",
            "12 | lstm_decoder                       | LSTM                            | 2.2 K \n",
            "13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 544   \n",
            "14 | post_lstm_add_norm_encoder         | AddNorm                         | 32    \n",
            "15 | static_enrichment                  | GatedResidualNetwork            | 1.4 K \n",
            "16 | multihead_attn                     | InterpretableMultiHeadAttention | 1.1 K \n",
            "17 | post_attn_gate_norm                | GateAddNorm                     | 576   \n",
            "18 | pos_wise_ff                        | GatedResidualNetwork            | 1.1 K \n",
            "19 | pre_output_gate_norm               | GateAddNorm                     | 576   \n",
            "20 | output_layer                       | Linear                          | 119   \n",
            "----------------------------------------------------------------------------------------\n",
            "23.0 K    Trainable params\n",
            "0         Non-trainable params\n",
            "23.0 K    Total params\n",
            "0.092     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.8/dist-packages/pytorch_lightning/trainer/trainer.py:1600: PossibleUserWarning: The number of training batches (30) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
            "  rank_zero_warn(\n",
            "Epoch 0:  97% 30/31 [00:03<00:00,  9.33it/s, loss=80.4, v_num=6, train_loss_step=61.00]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 0: 100% 31/31 [00:03<00:00,  9.42it/s, loss=80.4, v_num=6, train_loss_step=61.00, val_loss=117.0]\n",
            "Epoch 1:  10% 3/31 [00:00<00:02,  9.50it/s, loss=76.7, v_num=6, train_loss_step=54.70, val_loss=117.0, train_loss_epoch=79.90]"
          ]
        }
      ]
    }
  ]
}
